{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECmxcTJqGocF"
   },
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgW92cheKw0i"
   },
   "source": [
    "# **Data Spaces - Analysis of the Online Shoppers Purchasing Intention Dataset**\n",
    "\n",
    "**Martina Alutto, s265027**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgW92cheKw0i"
   },
   "source": [
    "**Introduction**\n",
    "\n",
    "The analysis that will be presented has been carried out on the dataset available online at the following link: https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset.\n",
    "\n",
    "This dataset consists of feature vectors belonging to 12,330 online sessions.\n",
    "The dataset was formed so that each session would belong to a different user in a 1-year period to avoid any tendency to a specific campaign, special day, user\n",
    "profile, or period. Some of these sessions on the site end with a purchase, while others do not.\n",
    "The dataset contains 18 features, where 10 are numerical and 8 are categorical attributes, there is also the 'Revenue' attribute, that indicates whether the session ends with shopping or not and this could be used as the class label.\n",
    "\n",
    "The columns containing users’s attributes are described in the following:\n",
    "\n",
    "\n",
    "*  \"Administrative\", \"Administrative_Duration\", \"Informational\", \"Informational _Duration\", \"ProductRelated\" and \"ProductRelated_Duration\" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. \n",
    "*  \"BounceRates\" for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server during that session.\n",
    "*  \"ExitRates\" for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session.\n",
    "*  \"PageValues\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. \n",
    "\n",
    "The previous three features represent the metrics measured by *Google Analytics* for each page in the e-commerce site. \n",
    "*   \"SpecialDay\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentine’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8.\n",
    "*   \"Month\" indicates the month in which the session took place.\n",
    "*   \"OperatingSystems\" and \"Browser\" are features indicating which operating system and browser are used by categorical values.\n",
    "*   \"Region\" indicates the geographic region of the user. \n",
    "*   \"TrafficType\" is a particular identifier type for any hierarchy of customer base: *user* or *account* are two of the most commonly defined traffic types. (In the dataset this is a categorical feature).\n",
    "*   \"VisitorType\" states the nature of the user as returning or new visitor.\n",
    "*   \"Weekend\" features indicates whether the session's date is weekend or not.\n",
    "\n",
    "As mentioned earlier, the boolean attribute \"Revenue\" is used to understand if the session in question ends with a purchase (and was therefore successful) or if instead it was limited to a search or a quick look at the products. The analysis of the users' behaviour could be very useful to predict it and to provide a better organisation of the site (e.g. a restyiling with more pop-ups that encourage purchase by users or more offers) in order to avoid leaving the site without shopping.\n",
    "\n",
    "The analysis carried out consists of a supervised classification problem, using the Python language and Jupyter Notebook. \n",
    "\n",
    "Among the main packages imported for the purposes of our analysis are to be reported: \n",
    "-  *pandas*: an open-source library prviding high-performance data structures and data analysis tools for manipulating numerical tables and time series.\n",
    "-  *numpy*: the fundamental package for scientific computing with Python.\n",
    "NumPy provides among other things: a powerful N-dimensional array object, sophisticated (broadcasting) functions, useful linear algebra and random number capabilities.\n",
    "-  *sklearn*: a free machine learning library providing tools for data mining.It features various algorithms like support vector machine, random forests, and k-neighbours.\n",
    "-  *matplotlib*: a comprehensive library for creating static, animated, and interactive visualizations.\n",
    "-  *seaborn*: a Python data visualization library based on *matplotlib*, providing an interface for statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "4xEWgC7OHEpe",
    "outputId": "393fb973-ce0d-4ab1-84fd-9e0fc16b58b5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "lDfpV4banFfh",
    "outputId": "e83ab22f-d6ab-4b6f-8993-e6aabe6cb7ca"
   },
   "outputs": [],
   "source": [
    "# TESINA DATA SPACES\n",
    "\n",
    "# Import libraries\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import sklearn\n",
    "from sklearn import decomposition, preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO \n",
    "\n",
    "from IPython.display import Image  \n",
    "#import pydotplus\n",
    "\n",
    "#import plotly\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.io as pio\n",
    "#import plotly.figure_factory as ff\n",
    "#from plotly.offline import init_notebook_mode\n",
    "#init_notebook_mode(connected=True) # to show plots in notebook\n",
    "\n",
    "# online plotly\n",
    "import chart_studio\n",
    "from chart_studio.plotly import plot, iplot\n",
    "chart_studio.tools.set_credentials_file(username='XXXXXXXXXXXXXX', api_key='XXXXXXXXXXXXXX')\n",
    "\n",
    "# offline plotly\n",
    "#from plotly.offline import plot, iplot\n",
    "\n",
    "# do not show any warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set the seed for the analysis\n",
    "SEED = 40\n",
    "\n",
    "# pandas option for the output style \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nBuRN8MDWz8"
   },
   "source": [
    "**Exploration and Preprocessing**\n",
    "\n",
    "After importing the dataset, we can move on to exploring it, we can take a look at the structure of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "1ruGo7rso91D",
    "outputId": "d193312c-d5d3-4ed5-9be0-e783e1f12901"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('/Users/Martina/Google Drive/online_shoppers_intention.csv') \n",
    "\n",
    "print('\\nDataset dimensions : ', data.shape)\n",
    "\n",
    "# Data analysis\n",
    "# Preview the first 5 lines of the loaded data \n",
    "print('This is a preview of the first 5 lines of the loaded dataset.\\n')\n",
    "print(data.head(5))\n",
    "\n",
    "#with open('/content/drive/My Drive/Colab Notebooks/Data Spaces/online_shoppers_intention.csv', newline='') as csvfile:\n",
    "#   lettore = csv.reader(csvfile, delimiter=\",\")\n",
    "#   header = next(lettore)\n",
    "#   print('\\nFeatures : ', header)\n",
    "\n",
    "# check for null values in the dataset\n",
    "print(\"\\nThere are \" + (\"some\" if data.isnull().values.any() else \"no\")  + \" null/missing values in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IwfA-8SmRYg0"
   },
   "source": [
    "In order to investigate the pair-wise correlations between two variables X and Y, we use the Pearson correlation. \n",
    "Let σ_{X}, σ_{Y} be the standard deviation of X,Y and the covariance cov(X,Y) = E[(X−E[X])(Y−E[Y])]. \n",
    "Then we can define the Pearson correlation as ρ_{X,Y}=cov(X,Y)σ_{X}σ_{Y}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "a7EFdOkFRVUI",
    "outputId": "7806b343-1185-409b-a165-1f3d520554e1"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "print('Correlation matrix between the dataset features.')\n",
    "corr = data.corr()\n",
    "ax = sns.heatmap(corr, vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), square=True)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHEienLdGXMA"
   },
   "source": [
    "The correlation matrix graph shows a strong positive correlation between the attributes \"BounceRates\" and \"ExitRates\". Let us remember that Bounce rate is the percentage of people who landed on a page and immediately left, so they are always one-page sessions. A high Bounce rate on a home page is usually a sign that something is wrong, but it’s really a matter of context. Instead Exit rate is the percentage of people who left your site from that page and exits may have viewed more than one page in a session. That means they may not have landed on that page, but simply found their way to it through site navigation. What is important is that like Bounce rates, high Exit rates can often reveal problem areas on your site and that's why we have a strong correlation between them. \n",
    "\n",
    "It's also clear that the attributes \"Administrative\", \"Informational\" and \"ProductRelated\" are quite positively correlated with their duration attributes, because the number of pages of a certain type visited during the session is related to the time spent on that type of pages. You can see a greater correlation in the case of product pages because, with the same number of pages of the 3 types, more time is spent on a product page where all its specifications and characteristics are looked at.\n",
    "\n",
    "We can also observe a quite high positive correlation between the \"PageValues\" feature and the label \"Revenue\", and this is what we expected because the objective of the first value is to give an idea of the page that has contributed most to the site's revenue. If a page has not been involved in any way in the e-commerce transaction, its Page Value is € 0, since the page has never been visited in a session where a transaction was made.\n",
    "-- **vedere se aggiungere altro** -- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CP3QTEtmmZkB"
   },
   "source": [
    "As seen previously with the previous of the first five lines of the loaded data, we can observe how the categorical attributes \"Month\", \"VisitorType\" and \"Weekend\" have string values but they can be easily transformed into numbers.\n",
    "\"Weekend\" is transformed by placing *0* if it was *False* and *1* if it was *True*; similarly \"VisitorType\" is set to *1* if it was a returning visitor and *0* if it is a new one. \n",
    "Instead \"Month\" is transformed using LabelEncoder which automatically converts each distinct label into an unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "SA7cbs1Q-5m5",
    "outputId": "d1df639a-907d-462a-83af-72e7323209ca"
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "data['Weekend'] = data['Weekend'].apply(lambda x: 0 if x=='False' else 1)\n",
    "data['VisitorType'] = data['VisitorType'].apply(lambda x: 0 if x=='New_Visitor' else 1)\n",
    "le = LabelEncoder()\n",
    "le.fit(data['Month'])\n",
    "data['Month'] = le.transform(data['Month'])\n",
    "\n",
    "print('This is a preview of the first 5 lines of the loaded dataset with the transformed attributes.\\n')\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "3qLmnL9POGGU",
    "outputId": "7b590276-18d8-4754-b762-bc5964ce280c"
   },
   "outputs": [],
   "source": [
    "print('\\n\\n')\n",
    "print('The following statistical measures can give us a statistical overview of the data.\\n')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D_k9ifuFq06F"
   },
   "source": [
    "In order to better understand this data, let us move on to a more in-depth exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "7VntY184rmuW",
    "outputId": "9c1b9b44-b5cb-48ab-ccb1-3a1283daf040"
   },
   "outputs": [],
   "source": [
    "colors = plotly.colors.DEFAULT_PLOTLY_COLORS\n",
    "revenue_dict = {False: \"No Revenue\", True: \"Revenue\"}\n",
    "y = data[\"Revenue\"].value_counts()\n",
    "\n",
    "d = [go.Bar(x=[revenue_dict[x] for x in y.index], y=y.values, marker = dict(color = colors[:len(y.index)]))]\n",
    "layout = go.Layout(\n",
    "    title='Revenue distribution over the total',\n",
    "    autosize=False,\n",
    "    width=400,\n",
    "    height=400,\n",
    "    yaxis=dict(\n",
    "        title='number of samples',\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=d, layout=layout)\n",
    "fig.show()\n",
    "#iplot(fig, filename='basic-bar3')\n",
    "\n",
    "revenue_percentage = data[\"Revenue\"].sum() * 100 / data[\"Revenue\"].shape[0]\n",
    "print(\"The Revenue percentage is %.3f%%.\" % revenue_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "uEZe4Mc0oVir",
    "outputId": "87e1f01b-581b-4ba2-dff9-a20631a7b615"
   },
   "outputs": [],
   "source": [
    "month_revenue = data.groupby([\"Month\", \"Revenue\"]).size().unstack()\n",
    "trace1 = go.Bar(\n",
    "    x=month_revenue.index,\n",
    "    y=month_revenue[0],\n",
    "    marker = dict(color = colors[0]),\n",
    "    name='No Revenue'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=month_revenue.index,\n",
    "    y=month_revenue[1],\n",
    "    marker = dict(color = colors[1]),\n",
    "    name='Revenue'\n",
    ")\n",
    "d2 = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Revenue Distribution for Month',\n",
    "    autosize=True,\n",
    "    barmode='stack',\n",
    "    margin=go.layout.Margin(l=50, r=50),\n",
    "    xaxis=dict(\n",
    "        title='Month',\n",
    "        tickangle=45\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of samples',\n",
    "        automargin=True,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=d2, layout=layout)\n",
    "fig.show()\n",
    "\n",
    "#revenue_percentage = data[\"Revenue\"].sum() * 100 / data[\"Revenue\"].shape[0]\n",
    "#print(\"The Revenue percentage is %.3f%%.\" % revenue_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "FdCQyXw7ow2-",
    "outputId": "e9f95b55-5fb8-4d8f-adc4-c7420d9748fc"
   },
   "outputs": [],
   "source": [
    "weekend_revenue = data.groupby([\"Weekend\", \"Revenue\"]).size().unstack()\n",
    "trace1 = go.Bar(\n",
    "    x=weekend_revenue.index,\n",
    "    y=weekend_revenue[0],\n",
    "    marker = dict(color = colors[0]),\n",
    "    name='No Revenue'\n",
    ")\n",
    "trace2 = go.Bar(\n",
    "    x=weekend_revenue.index,\n",
    "    y=weekend_revenue[1],\n",
    "    marker = dict(color = colors[1]),\n",
    "    name='Revenue'\n",
    ")\n",
    "d2 = [trace1, trace2]\n",
    "layout = go.Layout(\n",
    "    title='Revenue Distribution on Weekend',\n",
    "    autosize=True,\n",
    "    barmode='stack',\n",
    "    margin=go.layout.Margin(l=50, r=50),\n",
    "    xaxis=dict(\n",
    "        title='Weekend',\n",
    "        tickangle=45\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Number of samples',\n",
    "        automargin=True,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=d2, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "YZZnP-RnsBcR",
    "outputId": "de2cf2c7-36f5-4e0b-aa3e-b17494aa5e4a"
   },
   "outputs": [],
   "source": [
    "data[['BounceRates', 'Revenue']].groupby(['BounceRates'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n",
    "data[['ExitRates', 'Revenue']].groupby(['ExitRates'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n",
    "data[['Administrative', 'Revenue']].groupby(['Administrative'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n",
    "data[['Administrative_Duration', 'Revenue']].groupby(['Administrative_Duration'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n",
    "data[['Informational_Duration', 'Revenue']].groupby(['Informational_Duration'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n",
    "data[['ProductRelated_Duration', 'Revenue']].groupby(['ProductRelated_Duration'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n",
    "data[['VisitorType', 'Revenue']].groupby(['VisitorType'], as_index=False).mean().sort_values(by='Revenue', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "tqDh0NhPwd2q",
    "outputId": "74806a05-377d-47ba-b73b-04e26d417ae5"
   },
   "outputs": [],
   "source": [
    "data[['PageValues', 'Revenue']].groupby(['Revenue'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNGqyObSxEMC"
   },
   "source": [
    "Calculating the average of the attribute \"PagesValues\" for both sessions ended with purchase and sessions ended without purchase, we can see that the former is much higher than the latter. This confirms the quite good correlation that we noticed previously between the attributes \"PagesValues\" and \"Revenue\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uED9LZkykJp"
   },
   "source": [
    "Now we can save the attribute \"Revenue\" as label and exlude it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRlR8BRItoSB"
   },
   "outputs": [],
   "source": [
    "# Save attribute label and delete it from the dataset\n",
    "label = data['Revenue'][:]\n",
    "X = np.array(data.drop(['Revenue'], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54swQrUAzEcy"
   },
   "source": [
    "In order to reduce the dimensionality of our dataset, we could apply the PCA (Principal Component Analysis), i.e. a technique for deriving a low-dimensional set of features from a large set of variables. Given data points in a large space, it projects them into a lower dimensional space while preserving as much information as possible and maximizing the variance of the projected data. The chosen projection is the one that minimizes mean squared distance between data point and projections. The new space's principal component corrensponds to the points in the direction of the largest variance; each sbusequent principal component is orthogonal to the previous ones and it corresponds to points in the directions of the largest variance of the residual subspace. \n",
    "\n",
    "Given a set of data points, if we compute the covariance matrix E, the PCA basis vectors are the eigenvectors of E, therefore the larger eigenvalue corresponds to the more important eigenvectors. \n",
    "\n",
    "As it is a required condition for PCA analysis, we firstly have to standardize data, by subtracting the mean and scaling to unit variance with the *StandardScaler* of the sklearn library.\n",
    "\n",
    "Once have scaled data, we can perform the PCA and the amount of explained variance by each component and the cumulative explained variance in order to can choose in order to choose the most appropriate number of components for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZonnivGf6eFe"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(random_state=SEED)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "tot = sum(pca.explained_variance_) # total explained variance of all principal components\n",
    "var_exp = [(i / tot) * 100 for i in sorted(pca.explained_variance_, reverse=True)] # individual explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) # cumulative explained variance\n",
    "\n",
    "trace_cum_var_exp = go.Bar(\n",
    "    x=list(range(1, len(cum_var_exp) + 1)), \n",
    "    y=var_exp,\n",
    "    marker = dict(color = colors[0]),\n",
    "    name=\"individual explained variance\",\n",
    ")\n",
    "trace_ind_var_exp = go.Bar(\n",
    "    x=list(range(1, len(cum_var_exp) + 1)),\n",
    "    y=cum_var_exp,\n",
    "    marker = dict(color = colors[7]),\n",
    "    name=\"cumulative explained variance\",\n",
    ")\n",
    "d = [trace_cum_var_exp, trace_ind_var_exp]\n",
    "layout = go.Layout(\n",
    "    title='Individual and Cumulative Explained Variance',\n",
    "    autosize=True,\n",
    "    yaxis=dict(\n",
    "        title='percentage of explained variance',\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=\"principal components\",\n",
    "        dtick=1,\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "    ),\n",
    ")\n",
    "fig = go.Figure(data=d, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQbLHeWAzi1e"
   },
   "source": [
    "Covering more than **% of the total variance explained, we can choose a PCA with * components. \n",
    "\n",
    "From now on, we will carry out two types of analysis, the first taking into account the dimensional reduction implemented by the PCA and the second where the classifiers will be used directly on the original data space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "R_q-r5Y_N5s-",
    "outputId": "c550ad3e-3bc0-419e-9e09-d2baa2669832"
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "# Define the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA(random_state=SEED)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "print('\\n Percentage of variance explained by each of the selected components: {}'.format(pca.explained_variance_ratio_))\n",
    "print('\\n The singular values corresponding to each of the selected components: {}'.format(pca.singular_values_))\n",
    "principal_X = pd.DataFrame(data = data_pca, columns = ['principal component 1', 'principal component 2'])\n",
    "final_X = pd.concat([principal_X, label], axis = 1)\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 11)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 11)\n",
    "ax.set_title('2 component PCA', fontsize = 15)\n",
    "targets = [True, False]\n",
    "colors = ['c','m']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = final_X['Revenue'] == target\n",
    "    ax.scatter(final_X.loc[indicesToKeep, 'principal component 1']\n",
    "               , final_X.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "\n",
    "#LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "data_lda = lda.fit(data_scaled, label).transform(data_scaled)\n",
    "print('\\n Percentage of variance explained by each of the selected components: {}'.format(lda.explained_variance_ratio_))\n",
    "\n",
    "principal_X2 = pd.DataFrame(data = data_lda, columns = ['linear component 1'])\n",
    "final_X2 = pd.concat([principal_X2, label], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "B5JBkWvr8E6l",
    "outputId": "d4cb0a94-ef5c-4df5-f047-f8c6642603e2"
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "# Apply the function train_test_split\n",
    "X_train, X_test, target_train, target_test = train_test_split(X, label, test_size=0.5, train_size=0.5, random_state = 0)\n",
    "\n",
    "y = target_train\n",
    "\n",
    "h = 0.1  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "n_neighbors = 1\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf_knn.fit(X_train, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification k = %i\"% (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "O8W1C6Gx8uaz",
    "outputId": "72d459d2-86d2-4b16-fce5-f7bb08a679d0"
   },
   "outputs": [],
   "source": [
    "n_neighbors = 3\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf_knn.fit(X_train, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification k = %i\"% (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "I0oDYMXRriux",
    "outputId": "e0b3c58c-4248-4b50-ecb0-e115e72cb6a5"
   },
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf_knn.fit(X_train, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification k = %i\"% (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "25auCNMfrkGC",
    "outputId": "1bf4c66f-68e4-4eab-8e0a-1a96606813a2"
   },
   "outputs": [],
   "source": [
    "n_neighbors = 7\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf_knn.fit(X_train, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification k = %i\"% (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "8Q9AfXSy6E8G",
    "outputId": "7b23d6d8-3326-40d4-d183-373b7a6cc9cf"
   },
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf_knn.fit(X_train, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification k = %i\"% (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "5LffYD5w6uLt",
    "outputId": "5b11019e-cda3-48da-e5dd-9b5fcaeb15fe"
   },
   "outputs": [],
   "source": [
    "h = 5\n",
    "n_neighbors = 50\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "clf_knn.fit(X_train, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf_knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification k = %i\"% (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "uqZCpdFi8Tc5",
    "outputId": "8591a071-af3a-43ed-a404-26d7d2e0523c"
   },
   "outputs": [],
   "source": [
    "# KMEANS\n",
    "cluster = 5\n",
    "kmeans = KMeans(n_clusters=cluster, random_state=0).fit(X)\n",
    "labels = kmeans.labels_\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels.astype(np.float), s=30, cmap='Set1')\n",
    "plt.title(\"KMEANS classification k = %i\"% (cluster))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "c2D2y2dQDv3X",
    "outputId": "e8962b0e-a521-44ef-9266-f57fe962e639"
   },
   "outputs": [],
   "source": [
    "cluster = 4\n",
    "kmeans = KMeans(n_clusters=cluster, random_state=0).fit(dataset)\n",
    "labels = kmeans.labels_\n",
    "# Plot also the training points\n",
    "pca.fit(dataset)\n",
    "X = pca.transform(dataset)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels.astype(np.float), s=30, cmap='Set1')\n",
    "plt.title(\"KMEANS classification k = %i\"% (cluster))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mqF2IErlcl9K",
    "outputId": "d8ed97be-0fca-4d55-9109-0f381241dd68"
   },
   "outputs": [],
   "source": [
    "cluster = 2\n",
    "kmeans = KMeans(n_clusters=cluster, random_state=0).fit(X)\n",
    "labels = kmeans.labels_\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i])\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == label[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MbJPcNhEdq4h",
    "outputId": "cc59c84c-682f-442d-ea2f-b9d7ef2e0b0b"
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kmeans.fit(X_scaled)\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i])\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == label[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "nyQJfX5lfBjI",
    "outputId": "ef59ff06-d14b-46c8-b6c1-c803a6e6ef1d"
   },
   "outputs": [],
   "source": [
    "X1 = pca.fit(X).transform(X)\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=labels.astype(np.float), s=30, cmap='Set1')\n",
    "plt.title(\"KMEANS classification k = %i\"% (cluster))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "utLjSBbVfYue",
    "outputId": "952f2170-c0ba-42a2-9462-898b6361cdbc"
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pNfHxxhok1XN",
    "outputId": "bccce793-e941-44eb-9ef9-1efd28d8417e"
   },
   "outputs": [],
   "source": [
    "#KNN\n",
    "X_train, X_test, target_train, target_test = train_test_split(X_scaled, label, test_size=0.5, train_size=0.5, random_state = 0)\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, target_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8fYZPgc1paWf",
    "outputId": "70d3979a-d15b-4a88-e13e-a39393fad378"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, target_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2UKM2au_qh-x",
    "outputId": "c1fc2a38-9a00-4daf-f76c-ce3326d18dbd"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train, target_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "be6ZhWwwqqVd",
    "outputId": "6ae3d1e5-1699-4c3a-9354-5b522956f752"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X_train, target_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "66dYv_aAqs9M",
    "outputId": "934d9355-a9ee-4a7c-d46e-7bf46e3a7166"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=16)\n",
    "knn.fit(X_train, target_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oSuw8-jtqv6O",
    "outputId": "2435e3bd-b9b3-4306-df51-c5b1dbd6fc44"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train, target_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "PPMa8Q4Oq5Y_",
    "outputId": "e068f6ab-a73c-4651-bacd-f7d37a454dcb"
   },
   "outputs": [],
   "source": [
    "X1 = pca.fit(X).transform(X)\n",
    "X_train, X_test, target_train, target_test = train_test_split(X1, label, test_size=0.5, train_size=0.5, random_state = 0)\n",
    "y = target_train\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "knn.fit(X_train, target_train)\n",
    "\n",
    "h = 5  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"Classification k = 17\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HYuqhgKysFVW",
    "outputId": "d0fcb43e-4faf-44db-8b1b-b69f30eb039c"
   },
   "outputs": [],
   "source": [
    "# DECISION TREE\n",
    "X_train, X_test, target_train, target_test = train_test_split(X, label, test_size=0.5, train_size=0.5, random_state = 0)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "clf = clf.fit(X_train, target_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "colab_type": "code",
    "id": "foQa4j-9w1DH",
    "outputId": "94524ec2-d131-4940-c9fe-7916ab0a26a1"
   },
   "outputs": [],
   "source": [
    "feature_cols = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'OperatingSystems', 'Browser', 'Region', 'TrafficType']\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['True','False'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('revenues_depth3.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kvc_8NOBw9HH",
    "outputId": "6497e2d9-aead-43f6-dff9-4ce67f4747f3"
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(X_train, target_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "colab_type": "code",
    "id": "XM8oYyzXyDA0",
    "outputId": "b4256e0f-fd44-4fbb-c089-1908db5c0cec"
   },
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = feature_cols,class_names=['True','False'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('revenues_depth5.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "b_zvYz2lygTG",
    "outputId": "5dcfb980-c3d1-476c-aaf6-5eb41d67967b"
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, target_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "soejUwkWy7oC",
    "outputId": "a010e3de-c180-4ce7-baed-694487ef5ef5"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, target_train, target_test = train_test_split(X, label, test_size=0.5, train_size=0.5, random_state = 0)\n",
    "\n",
    "clf_svm = svm.SVC(kernel = 'linear', gamma='auto')\n",
    "clf_svm.fit(X_train, target_train)\n",
    "\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "O82YuH30osWf",
    "outputId": "a2faf997-e8ab-43e7-d075-563610d2becf"
   },
   "outputs": [],
   "source": [
    "accuracy = np.zeros((7,2))\n",
    "i = 0\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "  j = 0\n",
    "  for ker in ['linear', 'rbf']:\n",
    "    # Create an instance of SVC Classifier with linear kernel and fit the data.\n",
    "    clf_svm = svm.SVC(C = c, kernel = ker, gamma='auto')\n",
    "    clf_svm.fit(X_train, target_train)\n",
    "\n",
    "    y_pred = clf_svm.predict(X_test)\n",
    "    accuracy[i,j] = metrics.accuracy_score(target_test, y_pred)\n",
    "    j += 1\n",
    "  i += 1\n",
    "  \n",
    "print(accuracy)\n",
    "print(accuracy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "DxHn1mLA5rxA",
    "outputId": "6627beaf-23b5-4320-ac06-4b98062c9950"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression()\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred=logreg.predict(X_test)\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBc9pwaO7aI-"
   },
   "outputs": [],
   "source": [
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Tesina_Data_Spaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
